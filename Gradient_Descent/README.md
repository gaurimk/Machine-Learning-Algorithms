ğŸ“˜ Overview

Gradient Descent is an optimization algorithm used to minimize the cost (or loss) function in machine learning models. It iteratively adjusts the model parameters in the direction of the steepest descent of the cost function to reach the global minimum.

âš™ï¸ Working Principle

Initialize Parameters:
Start with random values for model parameters (weights and bias).

Compute Predictions:
Use current parameters to make predictions on the data.

Calculate Cost Function:
Evaluate how far the predictions are from actual values (e.g., Mean Squared Error).

Compute Gradients:
Find the derivative of the cost function with respect to each parameter.

Update Parameters:
Adjust parameters using the formula:

ğœƒ
:
=
ğœƒ
âˆ’
ğ›¼
âˆ‚
ğ½
(
ğœƒ
)
âˆ‚
ğœƒ
Î¸:=Î¸âˆ’Î±
âˆ‚Î¸
âˆ‚J(Î¸)
	â€‹


where

ğœƒ
Î¸: parameter (weight/bias)

ğ›¼
Î±: learning rate

ğ½
(
ğœƒ
)
J(Î¸): cost function

Repeat:
Continue until the cost function converges or a maximum number of iterations is reached.
