K-Nearest Neighbors (KNN) is a simple machine learning algorithm used for both classification and regression. It predicts the output for a new data point by finding the K nearest data points in the training set and using their values — by majority vote for classification or average for regression. It is a lazy learner, meaning it doesn’t build a model but makes predictions based on stored data. KNN is easy to understand and works well for small datasets, but it becomes slow with large data and is sensitive to feature scaling and irrelevant features.
